{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "# Initialize LLM\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.tools import tool\n",
    "from prompts import AgentPrompts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884d576",
   "metadata": {},
   "source": [
    "we assume that the agents will be predicting for the one quarter. whether it's good to invest in the next quarter. so we get earnings report for one quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae471e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def financialReportRagTool(company: str) -> str:\n",
    "    # Dummy implementation for illustration\n",
    "    return f\"Financial report for {company}\"\n",
    "\n",
    "@tool\n",
    "def getAnnualisedReturnTool(*args, **kwargs) -> str:\n",
    "    '''\n",
    "        Get the annualised return for a company\n",
    "    '''\n",
    "    return 0.1\n",
    "\n",
    "@tool\n",
    "def getAnnualisedVolatilityTool(*args, **kwargs) -> str:\n",
    "    '''\n",
    "        Get the annualised volatility for a company\n",
    "    '''\n",
    "    return 0.2\n",
    "\n",
    "@tool \n",
    "def getVolumeTool(*args, **kwargs) -> str:\n",
    "    '''\n",
    "        Get the volume for a company\n",
    "    '''\n",
    "    return 1000000\n",
    "\n",
    "@tool \n",
    "def getNewsBodyTool(*args, **kwargs) -> str:\n",
    "    '''\n",
    "        Get the news body for a company\n",
    "    '''\n",
    "    return \"we are happy with the company\"\n",
    "\n",
    "documentTool = Tool(\n",
    "                name=\"financialReportRagTool\",\n",
    "                description=\"Useful to get the financial reports of a compnay\",\n",
    "                func=financialReportRagTool,\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca3ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e491d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a simple LangGraph ReAct agent\n",
    "valuationAgent = create_react_agent(llm, tools=[getAnnualisedVolatilityTool, getAnnualisedReturnTool], prompt=AgentPrompts.valuationAgent.value)\n",
    "\n",
    "# Example: send a message\n",
    "response = valuationAgent.invoke({\"messages\": [(\"user\", \"hey, can you tell me the return and volatility of AAPL?\")]})\n",
    "print(response[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4075ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAgent = create_react_agent(llm, tools=[getNewsBodyTool], prompt=AgentPrompts.sentimentAgent.value)\n",
    "response = sentimentAgent.invoke({\"messages\": [(\"user\", \"hey, what does the news think about AAPL?\")]})\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fff89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentalAgent = create_react_agent(llm, tools=[documentTool], prompt=AgentPrompts.fundamentalAgent.value)\n",
    "response = sentimentAgent.invoke({\"messages\": [(\"user\", \"hey what's the earnings for AAPL?\")]})\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5277b60d",
   "metadata": {},
   "source": [
    "since MicroSoftAutoGen is being used for debate, I switched to AutoGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ab92c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(source='user', models_usage=None, metadata={}, content=\"Say 'Hello 123World!'\", type='TextMessage'), TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=43, completion_tokens=5), metadata={}, content='Hello 123World!', type='TextMessage')] stop_reason=None\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "async def main() -> None:\n",
    "    agent = AssistantAgent(\"assistant\", OpenAIChatCompletionClient(model=\"gpt-4o-mini\"))\n",
    "    print(await agent.run(task=\"Say 'Hello 123World!'\"))\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911fcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphaagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
